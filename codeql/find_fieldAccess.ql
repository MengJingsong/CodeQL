/* This is an automatically generated file
* @name Hello world
* @kind path-problem
* @problem.severity error
* @precision high
* @id java/example/hello-world
*/

import java
import semmle.code.java.dataflow.DataFlow
import semmle.code.java.dataflow.FlowSinks
 // import semmle.code.java.dataflow.DataFlow
 import semmle.code.java.dataflow.TaintTracking //TaintTracking
 // import codeql.dataflow.DataFlow //PathGraph

predicate stringSet(string s) {
  s = "datanode.https.port" or
  s = "dfs.balancer.address" or
  s = "dfs.balancer.block-move.timeout" or
  s = "dfs.balancer.dispatcherThreads" or
  s = "dfs.balancer.getBlocks.hot-time-interval" or
  s = "dfs.balancer.getBlocks.min-block-size" or
  s = "dfs.balancer.getBlocks.size" or
  s = "dfs.balancer.kerberos.principal" or
  s = "dfs.balancer.keytab.enabled" or
  s = "dfs.balancer.keytab.file" or
  s = "dfs.balancer.max-iteration-time" or
  s = "dfs.balancer.max-no-move-interval" or
  s = "dfs.balancer.max-size-to-move" or
  s = "dfs.balancer.movedWinWidth" or
  s = "dfs.balancer.moverThreads" or
  s = "dfs.balancer.service.interval" or
  s = "dfs.balancer.service.retries.on.exception" or
  s = "dfs.batched.ls.limit" or
  s = "dfs.block.access.key.update.interval" or
  s = "dfs.block.access.token.enable" or
  s = "dfs.block.access.token.lifetime" or
  s = "dfs.block.access.token.protobuf.enable" or
  s = "dfs.block.invalidate.limit" or
  s = "dfs.block.local-path-access.user" or
  s = "dfs.block.misreplication.processing.limit" or
  s = "dfs.block.placement.ec.classname" or
  s = "dfs.block.replicator.classname" or
  s = "dfs.block.scanner.skip.recent.accessed" or
  s = "dfs.block.scanner.volume.bytes.per.second" or
  s = "dfs.block.scanner.volume.join.timeout.ms" or
  s = "dfs.blockreport.incremental.intervalMsec" or
  s = "dfs.blockreport.initialDelay" or
  s = "dfs.blockreport.intervalMsec" or
  s = "dfs.blockreport.split.threshold" or
  s = "dfs.blocksize" or
  s = "dfs.bytes-per-checksum" or
  s = "dfs.cachereport.intervalMsec" or
  s = "dfs.checksum.combine.mode" or
  s = "dfs.checksum.ec.socket-timeout" or
  s = "dfs.checksum.type" or
  s = "dfs.client-write-packet-size" or
  s = "dfs.client.block.reader.remote.buffer.size" or
  s = "dfs.client.block.write.locateFollowingBlock.initial.delay.ms" or
  s = "dfs.client.block.write.locateFollowingBlock.max.delay.ms" or
  s = "dfs.client.block.write.locateFollowingBlock.retries" or
  s = "dfs.client.block.write.replace-datanode-on-failure.best-effort" or
  s = "dfs.client.block.write.replace-datanode-on-failure.enable" or
  s = "dfs.client.block.write.replace-datanode-on-failure.min-replication" or
  s = "dfs.client.block.write.replace-datanode-on-failure.policy" or
  s = "dfs.client.block.write.retries" or
  s = "dfs.client.cache.drop.behind.reads" or
  s = "dfs.client.cache.drop.behind.writes" or
  s = "dfs.client.cache.readahead" or
  s = "dfs.client.cached.conn.retry" or
  s = "dfs.client.congestion.backoff.max.time" or
  s = "dfs.client.congestion.backoff.mean.time" or
  s = "dfs.client.context" or
  s = "dfs.client.datanode-restart.timeout" or
  s = "dfs.client.deadnode.detection.enabled" or
  s = "dfs.client.deadnode.detection.idle.sleep.ms" or
  s = "dfs.client.deadnode.detection.probe.connection.timeout.ms" or
  s = "dfs.client.deadnode.detection.probe.deadnode.interval.ms" or
  s = "dfs.client.deadnode.detection.probe.deadnode.threads" or
  s = "dfs.client.deadnode.detection.probe.suspectnode.interval.ms" or
  s = "dfs.client.deadnode.detection.probe.suspectnode.threads" or
  s = "dfs.client.deadnode.detection.rpc.threads" or
  s = "dfs.client.domain.socket.data.traffic" or
  s = "dfs.client.failover.connection.retries" or
  s = "dfs.client.failover.connection.retries.on.timeouts" or
  s = "dfs.client.failover.lazy.resolved" or
  s = "dfs.client.failover.max.attempts" or
  s = "dfs.client.failover.proxy.provider" or
  s = "dfs.client.failover.random.order" or
  s = "dfs.client.failover.resolve-needed" or
  s = "dfs.client.failover.resolver.impl" or
  s = "dfs.client.failover.resolver.useFQDN" or
  s = "dfs.client.failover.sleep.base.millis" or
  s = "dfs.client.failover.sleep.max.millis" or
  s = "dfs.client.fsck.connect.timeout" or
  s = "dfs.client.fsck.read.timeout" or
  s = "dfs.client.hedged.read.threadpool.size" or
  s = "dfs.client.hedged.read.threshold.millis" or
  s = "dfs.client.https.keystore.resource" or
  s = "dfs.client.https.need-auth" or
  s = "dfs.client.key.provider.cache.expiry" or
  s = "dfs.client.local.interfaces" or
  s = "dfs.client.mark.slownode.as.badnode.threshold" or
  s = "dfs.client.max.block.acquire.failures" or
  s = "dfs.client.mmap.cache.size" or
  s = "dfs.client.mmap.cache.timeout.ms" or
  s = "dfs.client.mmap.enabled" or
  s = "dfs.client.mmap.retry.timeout.ms" or
  s = "dfs.client.output.stream.uniq.default.key" or
  s = "dfs.client.pipeline.recovery.max-retries" or
  s = "dfs.client.rbf.observer.read.enable" or
  s = "dfs.client.read.prefetch.size" or
  s = "dfs.client.read.short.circuit.replica.stale.threshold.ms" or
  s = "dfs.client.read.shortcircuit" or
  s = "dfs.client.read.shortcircuit.buffer.size" or
  s = "dfs.client.read.shortcircuit.skip.checksum" or
  s = "dfs.client.read.shortcircuit.streams.cache.expiry.ms" or
  s = "dfs.client.read.shortcircuit.streams.cache.size" or
  s = "dfs.client.read.striped.threadpool.size" or
  s = "dfs.client.read.uri.cache.enabled" or
  s = "dfs.client.read.use.cache.priority" or
  s = "dfs.client.refresh.read-block-locations.ms" or
  s = "dfs.client.refresh.read-block-locations.register-automatically" or
  s = "dfs.client.refresh.read-block-locations.threads" or
  s = "dfs.client.replica.accessor.builder.classes" or
  s = "dfs.client.retry.interval-ms.get-last-block-length" or
  s = "dfs.client.retry.max.attempts" or
  s = "dfs.client.retry.policy.enabled" or
  s = "dfs.client.retry.policy.spec" or
  s = "dfs.client.retry.times.get-last-block-length" or
  s = "dfs.client.retry.window.base" or
  s = "dfs.client.server-defaults.validity.period.ms" or
  s = "dfs.client.short.circuit.num" or
  s = "dfs.client.short.circuit.replica.stale.threshold.ms" or
  s = "dfs.client.slow.io.warning.threshold.ms" or
  s = "dfs.client.socket-timeout" or
  s = "dfs.client.socket.send.buffer.size" or
  s = "dfs.client.socketcache.capacity" or
  s = "dfs.client.socketcache.expiryMsec" or
  s = "dfs.client.test.drop.namenode.response.number" or
  s = "dfs.client.use.datanode.hostname" or
  s = "dfs.client.use.legacy.blockreader.local" or
  s = "dfs.client.write.byte-array-manager.count-limit" or
  s = "dfs.client.write.byte-array-manager.count-reset-time-period-ms" or
  s = "dfs.client.write.byte-array-manager.count-threshold" or
  s = "dfs.client.write.byte-array-manager.enabled" or
  s = "dfs.client.write.exclude.nodes.cache.expiry.interval.millis" or
  s = "dfs.client.write.max-packets-in-flight" or
  s = "dfs.client.write.recover.lease.on.close.exception" or
  s = "dfs.cluster.administrators" or
  s = "dfs.content-summary.limit" or
  s = "dfs.content-summary.sleep-microsec" or
  s = "dfs.data.transfer.client.tcpnodelay" or
  s = "dfs.data.transfer.max.packet.size" or
  s = "dfs.data.transfer.protection" or
  s = "dfs.data.transfer.saslproperties.resolver.class" or
  s = "dfs.data.transfer.server.tcpnodelay" or
  s = "dfs.datanode.address" or
  s = "dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction" or
  s = "dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold" or
  s = "dfs.datanode.balance.bandwidthPerSec" or
  s = "dfs.datanode.balance.max.concurrent.moves" or
  s = "dfs.datanode.block-pinning.enabled" or
  s = "dfs.datanode.block.id.layout.upgrade.threads" or
  s = "dfs.datanode.bp-ready.timeout" or
  s = "dfs.datanode.cache.revocation.polling.ms" or
  s = "dfs.datanode.cache.revocation.timeout.ms" or
  s = "dfs.datanode.cached-dfsused.check.interval.ms" or
  s = "dfs.datanode.data.dir" or
  s = "dfs.datanode.data.dir.perm" or
  s = "dfs.datanode.data.read.bandwidthPerSec" or
  s = "dfs.datanode.data.transfer.bandwidthPerSec" or
  s = "dfs.datanode.data.write.bandwidthPerSec" or
  s = "dfs.datanode.dataset.sublock.count" or
  s = "dfs.datanode.directoryscan.interval" or
  s = "dfs.datanode.directoryscan.max.notify.count" or
  s = "dfs.datanode.directoryscan.threads" or
  s = "dfs.datanode.directoryscan.throttle.limit.ms.per.sec" or
  s = "dfs.datanode.disk.check.min.gap" or
  s = "dfs.datanode.disk.check.timeout" or
  s = "dfs.datanode.dns.interface" or
  s = "dfs.datanode.dns.nameserver" or
  s = "dfs.datanode.drop.cache.behind.reads" or
  s = "dfs.datanode.drop.cache.behind.writes" or
  s = "dfs.datanode.du.reserved" or
  s = "dfs.datanode.du.reserved.calculator" or
  s = "dfs.datanode.du.reserved.pct" or
  s = "dfs.datanode.ec.reconstruct.read.bandwidthPerSec" or
  s = "dfs.datanode.ec.reconstruct.write.bandwidthPerSec" or
  s = "dfs.datanode.ec.reconstruction.stripedread.buffer.size" or
  s = "dfs.datanode.ec.reconstruction.stripedread.timeout.millis" or
  s = "dfs.datanode.ec.reconstruction.threads" or
  s = "dfs.datanode.ec.reconstruction.validation" or
  s = "dfs.datanode.ec.reconstruction.xmits.weight" or
  s = "dfs.datanode.failed.volumes.tolerated" or
  s = "dfs.datanode.fileio.profiling.sampling.percentage" or
  s = "dfs.datanode.fixed.volume.size" or
  s = "dfs.datanode.fsdataset.factory" or
  s = "dfs.datanode.fsdataset.volume.choosing.policy" or
  s = "dfs.datanode.fsdatasetasyncdisk.max.threads.per.volume" or
  s = "dfs.datanode.fsdatasetcache.max.threads.per.volume" or
  s = "dfs.datanode.handler.count" or
  s = "dfs.datanode.hostname" or
  s = "dfs.datanode.http.address" or
  s = "dfs.datanode.http.internal-proxy.port" or
  s = "dfs.datanode.https.address" or
  s = "dfs.datanode.httpserver.filter.handlers" or
  s = "dfs.datanode.ipc.address" or
  s = "dfs.datanode.kerberos.principal" or
  s = "dfs.datanode.keytab.file" or
  s = "dfs.datanode.lazywriter.interval.sec" or
  s = "dfs.datanode.lifeline.interval.seconds" or
  s = "dfs.datanode.lock.fair" or
  s = "dfs.datanode.lockmanager.trace" or
  s = "dfs.datanode.max.disks.to.report" or
  s = "dfs.datanode.max.locked.memory" or
  s = "dfs.datanode.max.nodes.to.report" or
  s = "dfs.datanode.max.slowdisks.to.exclude" or
  s = "dfs.datanode.max.transfer.threads" or
  s = "dfs.datanode.metrics.logger.period.seconds" or
  s = "dfs.datanode.min.outlier.detection.disks" or
  s = "dfs.datanode.min.outlier.detection.nodes" or
  s = "dfs.datanode.nameservices.resolution-enabled" or
  s = "dfs.datanode.nameservices.resolver.impl" or
  s = "dfs.datanode.network.counts.cache.max.size" or
  s = "dfs.datanode.oob.timeout-ms" or
  s = "dfs.datanode.outliers.report.interval" or
  s = "dfs.datanode.parallel.volumes.load.threads.num" or
  s = "dfs.datanode.peer.metrics.min.outlier.detection.samples" or
  s = "dfs.datanode.peer.stats.enabled" or
  s = "dfs.datanode.plugins" or
  s = "dfs.datanode.pmem.cache.dirs" or
  s = "dfs.datanode.pmem.cache.recovery" or
  s = "dfs.datanode.processcommands.threshold" or
  s = "dfs.datanode.ram.disk.replica.tracker" or
  s = "dfs.datanode.readahead.bytes" or
  s = "dfs.datanode.reconcile.blocks.batch.interval" or
  s = "dfs.datanode.reconcile.blocks.batch.size" or
  s = "dfs.datanode.replica.cache.expiry.time" or
  s = "dfs.datanode.replica.cache.root.dir" or
  s = "dfs.datanode.reserve-for-archive.default.percentage" or
  s = "dfs.datanode.restart.replica.expiration" or
  s = "dfs.datanode.round-robin-volume-choosing-policy.additional-available-space" or
  s = "dfs.datanode.same-disk-tiering.capacity-ratio.percentage" or
  s = "dfs.datanode.same-disk-tiering.enabled" or
  s = "dfs.datanode.scan.period.hours" or
  s = "dfs.datanode.shared.file.descriptor.paths" or
  s = "dfs.datanode.slow.io.warning.threshold.ms" or
  s = "dfs.datanode.slowdisk.low.threshold.ms" or
  s = "dfs.datanode.slowpeer.low.threshold.ms" or
  s = "dfs.datanode.socket.reuse.keepalive" or
  s = "dfs.datanode.socket.write.timeout" or
  s = "dfs.datanode.sync.behind.writes" or
  s = "dfs.datanode.sync.behind.writes.in.background" or
  s = "dfs.datanode.transfer.socket.recv.buffer.size" or
  s = "dfs.datanode.transfer.socket.send.buffer.size" or
  s = "dfs.datanode.transferTo.allowed" or
  s = "dfs.datanode.use.datanode.hostname" or
  s = "dfs.datanode.volumes.replica-add.threadpool.size" or
  s = "dfs.default.chunk.view.size" or
  s = "dfs.disk.balancer.block.tolerance.percent" or
  s = "dfs.disk.balancer.enabled" or
  s = "dfs.disk.balancer.max.disk.errors" or
  s = "dfs.disk.balancer.max.disk.throughputInMBperSec" or
  s = "dfs.disk.balancer.plan.threshold.percent" or
  s = "dfs.disk.balancer.plan.valid.interval" or
  s = "dfs.domain.socket.disable.interval.seconds" or
  s = "dfs.domain.socket.path" or
  s = "dfs.edit.log.transfer.bandwidthPerSec" or
  s = "dfs.edit.log.transfer.timeout" or
  s = "dfs.encrypt.data.overwrite.downstream.derived.qop" or
  s = "dfs.encrypt.data.overwrite.downstream.new.qop" or
  s = "dfs.encrypt.data.transfer" or
  s = "dfs.encrypt.data.transfer.algorithm" or
  s = "dfs.encrypt.data.transfer.cipher.key.bitlength" or
  s = "dfs.encrypt.data.transfer.cipher.suites" or
  s = "dfs.ha.allow.stale.reads" or
  s = "dfs.ha.automatic-failover.enabled" or
  s = "dfs.ha.fencing.methods" or
  s = "dfs.ha.log-roll.period" or
  s = "dfs.ha.namenode.id" or
  s = "dfs.ha.namenodes.EXAMPLENAMESERVICE" or
  s = "dfs.ha.nn.not-become-active-in-safemode" or
  s = "dfs.ha.standby.checkpoints" or
  s = "dfs.ha.tail-edits.in-progress" or
  s = "dfs.ha.tail-edits.namenode-retries" or
  s = "dfs.ha.tail-edits.period" or
  s = "dfs.ha.tail-edits.period.backoff-max" or
  s = "dfs.ha.tail-edits.rolledits.timeout" or
  s = "dfs.ha.zkfc.client.ssl.enabled" or
  s = "dfs.ha.zkfc.nn.http.timeout.ms" or
  s = "dfs.ha.zkfc.port" or
  s = "dfs.heartbeat.interval" or
  s = "dfs.hosts" or
  s = "dfs.hosts.exclude" or
  s = "dfs.hosts.timeout" or
  s = "dfs.http.client.failover.max.attempts" or
  s = "dfs.http.client.failover.sleep.base.millis" or
  s = "dfs.http.client.failover.sleep.max.millis" or
  s = "dfs.http.client.retry.max.attempts" or
  s = "dfs.http.client.retry.policy.enabled" or
  s = "dfs.http.client.retry.policy.spec" or
  s = "dfs.http.policy" or
  s = "dfs.https.server.keystore.resource" or
  s = "dfs.image.compress" or
  s = "dfs.image.compression.codec" or
  s = "dfs.image.parallel.inode.threshold" or
  s = "dfs.image.parallel.load" or
  s = "dfs.image.parallel.target.sections" or
  s = "dfs.image.parallel.threads" or
  s = "dfs.image.transfer-bootstrap-standby.bandwidthPerSec" or
  s = "dfs.image.transfer.bandwidthPerSec" or
  s = "dfs.image.transfer.chunksize" or
  s = "dfs.image.transfer.timeout" or
  s = "dfs.internal.nameservices" or
  s = "dfs.journalnode.edit-cache-size.bytes" or
  s = "dfs.journalnode.edit-cache-size.fraction" or
  s = "dfs.journalnode.edits.dir" or
  s = "dfs.journalnode.edits.dir.perm" or
  s = "dfs.journalnode.enable.sync" or
  s = "dfs.journalnode.enable.sync.format" or
  s = "dfs.journalnode.handler.count" or
  s = "dfs.journalnode.http-address" or
  s = "dfs.journalnode.http-bind-host" or
  s = "dfs.journalnode.https-address" or
  s = "dfs.journalnode.https-bind-host" or
  s = "dfs.journalnode.kerberos.internal.spnego.principal" or
  s = "dfs.journalnode.kerberos.principal" or
  s = "dfs.journalnode.keytab.file" or
  s = "dfs.journalnode.rpc-address" or
  s = "dfs.journalnode.rpc-bind-host" or
  s = "dfs.journalnode.sync.interval" or
  s = "dfs.lock.suppress.warning.interval" or
  s = "dfs.ls.limit" or
  s = "dfs.metrics.percentiles.intervals" or
  s = "dfs.mover.address" or
  s = "dfs.mover.kerberos.principal" or
  s = "dfs.mover.keytab.enabled" or
  s = "dfs.mover.keytab.file" or
  s = "dfs.mover.max-no-move-interval" or
  s = "dfs.mover.movedWinWidth" or
  s = "dfs.mover.moverThreads" or
  s = "dfs.mover.retry.max.attempts" or
  s = "dfs.namenode.access-control-enforcer-reporting-threshold-ms" or
  s = "dfs.namenode.accesstime.precision" or
  s = "dfs.namenode.acls.enabled" or
  s = "dfs.namenode.audit.log.debug.cmdlist" or
  s = "dfs.namenode.audit.log.token.tracking.id" or
  s = "dfs.namenode.audit.log.with.remote.port" or
  s = "dfs.namenode.audit.loggers" or
  s = "dfs.namenode.available-space-block-placement-policy.balance-local-node" or
  s = "dfs.namenode.available-space-block-placement-policy.balanced-space-preference-fraction" or
  s = "dfs.namenode.available-space-block-placement-policy.balanced-space-tolerance" or
  s = "dfs.namenode.available-space-block-placement-policy.balanced-space-tolerance-limit" or
  s = "dfs.namenode.available-space-rack-fault-tolerant-block-placement-policy.balanced-space-preference-fraction" or
  s = "dfs.namenode.available-space-rack-fault-tolerant-block-placement-policy.balanced-space-tolerance" or
  s = "dfs.namenode.avoid.read.slow.datanode" or
  s = "dfs.namenode.avoid.read.stale.datanode" or
  s = "dfs.namenode.avoid.write.stale.datanode" or
  s = "dfs.namenode.backup.address" or
  s = "dfs.namenode.backup.dnrpc-address" or
  s = "dfs.namenode.backup.http-address" or
  s = "dfs.namenode.block-placement-policy.default.prefer-local-node" or
  s = "dfs.namenode.block-placement-policy.exclude-slow-nodes.enabled" or
  s = "dfs.namenode.block-placement.min-blocks-for.write" or
  s = "dfs.namenode.block.deletion.lock.threshold.ms" or
  s = "dfs.namenode.block.deletion.unlock.interval.ms" or
  s = "dfs.namenode.blockreport.max.lock.hold.time" or
  s = "dfs.namenode.blockreport.queue.size" or
  s = "dfs.namenode.blocks.per.postponedblocks.rescan" or
  s = "dfs.namenode.caching.enabled" or
  s = "dfs.namenode.checkpoint.check.period" or
  s = "dfs.namenode.checkpoint.check.quiet-multiplier" or
  s = "dfs.namenode.checkpoint.dir" or
  s = "dfs.namenode.checkpoint.edits.dir" or
  s = "dfs.namenode.checkpoint.max-retries" or
  s = "dfs.namenode.checkpoint.period" or
  s = "dfs.namenode.checkpoint.txns" or
  s = "dfs.namenode.corrupt.block.delete.immediately.enabled" or
  s = "dfs.namenode.crm.checklocktime.enable" or
  s = "dfs.namenode.crm.maxlocktime.ms" or
  s = "dfs.namenode.crm.sleeptime.ms" or
  s = "dfs.namenode.datanode.registration.ip-hostname-check" or
  s = "dfs.namenode.decommission.backoff.monitor.pending.blocks.per.lock" or
  s = "dfs.namenode.decommission.backoff.monitor.pending.limit" or
  s = "dfs.namenode.decommission.blocks.per.interval" or
  s = "dfs.namenode.decommission.interval" or
  s = "dfs.namenode.decommission.max.concurrent.tracked.nodes" or
  s = "dfs.namenode.decommission.monitor.class" or
  s = "dfs.namenode.delegation.key.update-interval" or
  s = "dfs.namenode.delegation.token.always-use" or
  s = "dfs.namenode.delegation.token.max-lifetime" or
  s = "dfs.namenode.delegation.token.renew-interval" or
  s = "dfs.namenode.ec.policies.max.cellsize" or
  s = "dfs.namenode.ec.system.default.policy" or
  s = "dfs.namenode.ec.userdefined.policy.allowed" or
  s = "dfs.namenode.edekcacheloader.initial.delay.ms" or
  s = "dfs.namenode.edekcacheloader.interval.ms" or
  s = "dfs.namenode.edekcacheloader.max-retries" or
  s = "dfs.namenode.edit.log.autoroll.check.interval.ms" or
  s = "dfs.namenode.edit.log.autoroll.multiplier.threshold" or
  s = "dfs.namenode.edits.asynclogging" or
  s = "dfs.namenode.edits.asynclogging.pending.queue.size" or
  s = "dfs.namenode.edits.dir" or
  s = "dfs.namenode.edits.dir.minimum" or
  s = "dfs.namenode.edits.dir.required" or
  s = "dfs.namenode.edits.journal-plugin" or
  s = "dfs.namenode.edits.journal-plugin.qjournal" or
  s = "dfs.namenode.edits.noeditlogchannelflush" or
  s = "dfs.namenode.edits.qjournals.resolution-enabled" or
  s = "dfs.namenode.edits.qjournals.resolver.impl" or
  s = "dfs.namenode.enable.log.stale.datanode" or
  s = "dfs.namenode.enable.retrycache" or
  s = "dfs.namenode.excess.redundancy.timeout-sec" or
  s = "dfs.namenode.excess.redundancy.timeout.check.limit" or
  s = "dfs.namenode.file.close.num-committed-allowed" or
  s = "dfs.namenode.fs-limits.max-blocks-per-file" or
  s = "dfs.namenode.fs-limits.max-component-length" or
  s = "dfs.namenode.fs-limits.max-directory-items" or
  s = "dfs.namenode.fs-limits.max-xattr-size" or
  s = "dfs.namenode.fs-limits.max-xattrs-per-inode" or
  s = "dfs.namenode.fs-limits.min-block-size" or
  s = "dfs.namenode.fslock.fair" or
  s = "dfs.namenode.full.block.report.lease.length.ms" or
  s = "dfs.namenode.gc.time.monitor.enable" or
  s = "dfs.namenode.gc.time.monitor.observation.window.ms" or
  s = "dfs.namenode.gc.time.monitor.sleep.interval.ms" or
  s = "dfs.namenode.get-blocks.check.operation" or
  s = "dfs.namenode.get-blocks.max-qps" or
  s = "dfs.namenode.handler.count" or
  s = "dfs.namenode.heartbeat.recheck-interval" or
  s = "dfs.namenode.hosts.provider.classname" or
  s = "dfs.namenode.http-address" or
  s = "dfs.namenode.http-bind-host" or
  s = "dfs.namenode.https-address" or
  s = "dfs.namenode.https-bind-host" or
  s = "dfs.namenode.inode.attributes.provider.bypass.users" or
  s = "dfs.namenode.inode.attributes.provider.class" or
  s = "dfs.namenode.inotify.max.events.per.rpc" or
  s = "dfs.namenode.invalidate.work.pct.per.iteration" or
  s = "dfs.namenode.ip-proxy-users" or
  s = "dfs.namenode.kerberos.internal.spnego.principal" or
  s = "dfs.namenode.kerberos.principal" or
  s = "dfs.namenode.kerberos.principal.pattern" or
  s = "dfs.namenode.keytab.file" or
  s = "dfs.namenode.lazypersist.file.scrub.interval.sec" or
  s = "dfs.namenode.lease-hard-limit-sec" or
  s = "dfs.namenode.lease-recheck-interval-ms" or
  s = "dfs.namenode.legacy-oiv-image.dir" or
  s = "dfs.namenode.lifeline.handler.count" or
  s = "dfs.namenode.lifeline.handler.ratio" or
  s = "dfs.namenode.lifeline.rpc-address" or
  s = "dfs.namenode.lifeline.rpc-bind-host" or
  s = "dfs.namenode.list.cache.directives.num.responses" or
  s = "dfs.namenode.list.cache.pools.num.responses" or
  s = "dfs.namenode.list.encryption.zones.num.responses" or
  s = "dfs.namenode.list.openfiles.num.responses" or
  s = "dfs.namenode.list.reencryption.status.num.responses" or
  s = "dfs.namenode.lock.detailed-metrics.enabled" or
  s = "dfs.namenode.maintenance.replication.min" or
  s = "dfs.namenode.max-corrupt-file-blocks-returned" or
  s = "dfs.namenode.max-lock-hold-to-release-lease-ms" or
  s = "dfs.namenode.max-num-blocks-to-log" or
  s = "dfs.namenode.max.extra.edits.segments.retained" or
  s = "dfs.namenode.max.full.block.report.leases" or
  s = "dfs.namenode.max.objects" or
  s = "dfs.namenode.max.op.size" or
  s = "dfs.namenode.max.slowpeer.collect.nodes" or
  s = "dfs.namenode.metrics.logger.period.seconds" or
  s = "dfs.namenode.missing.checkpoint.periods.before.shutdown" or
  s = "dfs.namenode.name.cache.threshold" or
  s = "dfs.namenode.name.dir" or
  s = "dfs.namenode.name.dir.restore" or
  s = "dfs.namenode.num.checkpoints.retained" or
  s = "dfs.namenode.num.extra.edits.retained" or
  s = "dfs.namenode.observer.enabled" or
  s = "dfs.namenode.path.based.cache.block.map.allocation.percent" or
  s = "dfs.namenode.path.based.cache.refresh.interval.ms" or
  s = "dfs.namenode.path.based.cache.retry.interval.ms" or
  s = "dfs.namenode.plugins" or
  s = "dfs.namenode.posix.acl.inheritance.enabled" or
  s = "dfs.namenode.provided.enabled" or
  s = "dfs.namenode.quota.init-threads" or
  s = "dfs.namenode.read-lock-reporting-threshold-ms" or
  s = "dfs.namenode.read.considerLoad" or
  s = "dfs.namenode.read.considerStorageType" or
  s = "dfs.namenode.reconstruction.pending.timeout-sec" or
  s = "dfs.namenode.redundancy.considerLoad" or
  s = "dfs.namenode.redundancy.considerLoad.factor" or
  s = "dfs.namenode.redundancy.considerLoadByStorageType" or
  s = "dfs.namenode.redundancy.considerLoadByVolume" or
  s = "dfs.namenode.redundancy.interval.seconds" or
  s = "dfs.namenode.redundancy.queue.restart.iterations" or
  s = "dfs.namenode.reencrypt.batch.size" or
  s = "dfs.namenode.reencrypt.edek.threads" or
  s = "dfs.namenode.reencrypt.sleep.interval" or
  s = "dfs.namenode.reencrypt.throttle.limit.handler.ratio" or
  s = "dfs.namenode.reencrypt.throttle.limit.updater.ratio" or
  s = "dfs.namenode.reject-unresolved-dn-topology-mapping" or
  s = "dfs.namenode.remove.dead.datanode.batchnum" or
  s = "dfs.namenode.replication.max-streams" or
  s = "dfs.namenode.replication.max-streams-hard-limit" or
  s = "dfs.namenode.replication.min" or
  s = "dfs.namenode.replication.work.multiplier.per.iteration" or
  s = "dfs.namenode.resource.check.interval" or
  s = "dfs.namenode.resource.checked.volumes" or
  s = "dfs.namenode.resource.checked.volumes.minimum" or
  s = "dfs.namenode.resource.du.reserved" or
  s = "dfs.namenode.retrycache.expirytime.millis" or
  s = "dfs.namenode.retrycache.heap.percent" or
  s = "dfs.namenode.rpc-address" or
  s = "dfs.namenode.rpc-address.auxiliary-ports" or
  s = "dfs.namenode.rpc-bind-host" or
  s = "dfs.namenode.safemode.extension" or
  s = "dfs.namenode.safemode.min.datanodes" or
  s = "dfs.namenode.safemode.recheck.interval" or
  s = "dfs.namenode.safemode.replication.min" or
  s = "dfs.namenode.safemode.threshold-pct" or
  s = "dfs.namenode.secondary.http-address" or
  s = "dfs.namenode.secondary.https-address" or
  s = "dfs.namenode.send.qop.enabled" or
  s = "dfs.namenode.service.handler.count" or
  s = "dfs.namenode.servicerpc-address" or
  s = "dfs.namenode.servicerpc-bind-host" or
  s = "dfs.namenode.shared.edits.dir" or
  s = "dfs.namenode.slowpeer.collect.interval" or
  s = "dfs.namenode.snapshot.capture.openfiles" or
  s = "dfs.namenode.snapshot.filesystem.limit" or
  s = "dfs.namenode.snapshot.max.limit" or
  s = "dfs.namenode.snapshot.skip.capture.accesstime-only-change" or
  s = "dfs.namenode.snapshot.skiplist.interval" or
  s = "dfs.namenode.snapshot.skiplist.max.levels" or
  s = "dfs.namenode.snapshotdiff.allow.snap-root-descendant" or
  s = "dfs.namenode.snapshotdiff.listing.limit" or
  s = "dfs.namenode.stale.datanode.interval" or
  s = "dfs.namenode.stale.datanode.minimum.interval" or
  s = "dfs.namenode.startup.delay.block.deletion.sec" or
  s = "dfs.namenode.state.context.enabled" or
  s = "dfs.namenode.storage.dir.perm" or
  s = "dfs.namenode.support.allow.format" or
  s = "dfs.namenode.top.enabled" or
  s = "dfs.namenode.top.num.users" or
  s = "dfs.namenode.top.window.num.buckets" or
  s = "dfs.namenode.top.windows.minutes" or
  s = "dfs.namenode.upgrade.domain.factor" or
  s = "dfs.namenode.write-lock-reporting-threshold-ms" or
  s = "dfs.namenode.write.stale.datanode.ratio" or
  s = "dfs.namenode.xattrs.enabled" or
  s = "dfs.nameservice.id" or
  s = "dfs.nameservices" or
  s = "dfs.net.topology.impl" or
  s = "dfs.permissions.ContentSummary.subAccess" or
  s = "dfs.permissions.allow.owner.set.quota" or
  s = "dfs.permissions.enabled" or
  s = "dfs.permissions.superusergroup" or
  s = "dfs.pipeline.congestion.ratio" or
  s = "dfs.pipeline.ecn" or
  s = "dfs.pipeline.slownode" or
  s = "dfs.protected.subdirectories.enable" or
  s = "dfs.provided.acls.import.enabled" or
  s = "dfs.provided.aliasmap.class" or
  s = "dfs.provided.aliasmap.inmemory.batch-size" or
  s = "dfs.provided.aliasmap.inmemory.dnrpc-address" or
  s = "dfs.provided.aliasmap.inmemory.enabled" or
  s = "dfs.provided.aliasmap.inmemory.leveldb.dir" or
  s = "dfs.provided.aliasmap.inmemory.rpc.bind-host" or
  s = "dfs.provided.aliasmap.inmemory.server.log" or
  s = "dfs.provided.aliasmap.leveldb.path" or
  s = "dfs.provided.aliasmap.load.retries" or
  s = "dfs.provided.aliasmap.text.codec" or
  s = "dfs.provided.aliasmap.text.delimiter" or
  s = "dfs.provided.aliasmap.text.read.file" or
  s = "dfs.provided.aliasmap.text.write.dir" or
  s = "dfs.provided.storage.id" or
  s = "dfs.qjm.operations.timeout" or
  s = "dfs.qjournal.accept-recovery.timeout.ms" or
  s = "dfs.qjournal.finalize-segment.timeout.ms" or
  s = "dfs.qjournal.get-journal-state.timeout.ms" or
  s = "dfs.qjournal.http.open.timeout.ms" or
  s = "dfs.qjournal.http.read.timeout.ms" or
  s = "dfs.qjournal.new-epoch.timeout.ms" or
  s = "dfs.qjournal.parallel-read.num-threads" or
  s = "dfs.qjournal.prepare-recovery.timeout.ms" or
  s = "dfs.qjournal.queued-edits.limit.mb" or
  s = "dfs.qjournal.select-input-streams.timeout.ms" or
  s = "dfs.qjournal.start-segment.timeout.ms" or
  s = "dfs.qjournal.write-txns.timeout.ms" or
  s = "dfs.quota.by.storage.type.enabled" or
  s = "dfs.reformat.disabled" or
  s = "dfs.replication" or
  s = "dfs.replication.max" or
  s = "dfs.secondary.namenode.kerberos.internal.spnego.principal" or
  s = "dfs.secondary.namenode.kerberos.principal" or
  s = "dfs.secondary.namenode.keytab.file" or
  s = "dfs.short.circuit.shared.memory.watcher.interrupt.check.ms" or
  s = "dfs.storage.default.policy" or
  s = "dfs.storage.policy.enabled" or
  s = "dfs.storage.policy.permissions.superuser-only" or
  s = "dfs.storage.policy.satisfier.address" or
  s = "dfs.storage.policy.satisfier.datanode.cache.refresh.interval.ms" or
  s = "dfs.storage.policy.satisfier.kerberos.principal" or
  s = "dfs.storage.policy.satisfier.keytab.file" or
  s = "dfs.storage.policy.satisfier.max.outstanding.paths" or
  s = "dfs.storage.policy.satisfier.mode" or
  s = "dfs.storage.policy.satisfier.move.task.retry.max.attempts" or
  s = "dfs.storage.policy.satisfier.queue.limit" or
  s = "dfs.storage.policy.satisfier.recheck.timeout.millis" or
  s = "dfs.storage.policy.satisfier.retry.max.attempts" or
  s = "dfs.storage.policy.satisfier.self.retry.timeout.millis" or
  s = "dfs.storage.policy.satisfier.work.multiplier.per.iteration" or
  s = "dfs.stream-buffer-size" or
  s = "dfs.trustedchannel.resolver.class" or
  s = "dfs.use.dfs.network.topology" or
  s = "dfs.user.home.dir.prefix" or
  s = "dfs.web.authentication.kerberos.keytab" or
  s = "dfs.web.authentication.kerberos.principal" or
  s = "dfs.web.authentication.simple.anonymous.allowed" or
  s = "dfs.web.ugi" or
  s = "dfs.webhdfs.acl.provider.permission.pattern" or
  s = "dfs.webhdfs.netty.high.watermark" or
  s = "dfs.webhdfs.netty.low.watermark" or
  s = "dfs.webhdfs.oauth2.access.token.provider" or
  s = "dfs.webhdfs.oauth2.client.id" or
  s = "dfs.webhdfs.oauth2.enabled" or
  s = "dfs.webhdfs.oauth2.refresh.url" or
  s = "dfs.webhdfs.rest-csrf.browser-useragents-regex" or
  s = "dfs.webhdfs.rest-csrf.custom-header" or
  s = "dfs.webhdfs.rest-csrf.enabled" or
  s = "dfs.webhdfs.rest-csrf.methods-to-ignore" or
  s = "dfs.webhdfs.socket.connect-timeout" or
  s = "dfs.webhdfs.socket.read-timeout" or
  s = "dfs.webhdfs.ugi.expire.after.access" or
  s = "dfs.webhdfs.use.ipc.callq" or
  s = "dfs.webhdfs.user.provider.user.pattern" or
  s = "dfs.xframe.enabled" or
  s = "dfs.xframe.value" or
  s = "hadoop.fuse.connection.timeout" or
  s = "hadoop.fuse.timer.period" or
  s = "hadoop.hdfs.configuration.version" or
  s = "hadoop.user.group.metrics.percentiles.intervals" or
  s = "httpfs.buffer.size" or
  s = "nfs.allow.insecure.ports" or
  s = "nfs.dump.dir" or
  s = "nfs.kerberos.principal" or
  s = "nfs.keytab.file" or
  s = "nfs.mountd.port" or
  s = "nfs.rtmax" or
  s = "nfs.server.port" or
  s = "nfs.wtmax" or
  s = "ssl.server.keystore.keypassword" or
  s = "ssl.server.keystore.location" or
  s = "ssl.server.keystore.password" or
  s = "ssl.server.truststore.location" or
  s = "ssl.server.truststore.password"  
}

module MyFlowConfiguration implements DataFlow::ConfigSig {
  predicate isSource(DataFlow::Node source) {
    // exists(StringLiteral sl, Method m, MethodCall mc, int index |
    
    //   mc.getMethod() = m and
    //   mc.getArgument(index) = sl and
    //   stringSet(sl.getValue()) and               
    //   source.asExpr() = mc.getArgument(index)  
    // ) or 
    exists(Assignment assign, StringLiteral sl |
      stringSet(sl.getValue()) and 
      sl = assign.getRhs() and
      source.asExpr() = sl
    )
  }
  
  predicate isSink(DataFlow::Node sink) {
      exists(MethodCall call, int index |
        sink.asExpr() = call.getArgument(index) and
        not sink.asExpr().toString().matches("newName") and
        //call.getMethod().getName().matches("get%") and 
        sink.asExpr().toString().matches("DFS%")
      )
    }
}

module MyFlow = TaintTracking::Global<MyFlowConfiguration>;
import MyFlow::PathGraph

from MyFlow::PathNode source, MyFlow::PathNode sink
where MyFlow::flowPath(source, sink)
select
  source,
  source.getNode().asExpr(),
  source.getNode().asExpr().getParent(),
  source.getNode().asExpr().getEnclosingCallable(),
  source.getNode().getEnclosingCallable().getDeclaringType(),
  sink,
  sink.getNode().asExpr(),
  sink.getNode().asExpr().getParent(),
  sink.getNode().asExpr().getEnclosingCallable(),
  sink.getNode().getEnclosingCallable().getDeclaringType()